{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SIGNORILEG\\OneDrive - Links S.p.A\\Documenti\\GitHub\\RAG-with-LLamaIndex-Open\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"c:/Users/SIGNORILEG/OneDrive - Links S.p.A/Documenti/GitHub/RAG-with-LLamaIndex-Open\")\n",
    "cwd = os.getcwd()\n",
    "\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "no such file: '.\\Docs\\ongitudinal Data Analysis - Master of Science in Biostatistics by Slidesgo.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8980\\2399680445.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpdf_ingestion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpdf_ingestion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace_tables_in_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.\\Docs\\ongitudinal Data Analysis - Master of Science in Biostatistics by Slidesgo.pdf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\SIGNORILEG\\OneDrive - Links S.p.A\\Documenti\\GitHub\\RAG-with-LLamaIndex-Open\\pdf_ingestion.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(pdf_path)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mreplace_tables_in_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mdoc_fitz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mtext_chunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     model = lp.models.Detectron2LayoutModel(\n",
      "\u001b[1;32mc:\\Users\\SIGNORILEG\\OneDrive - Links S.p.A\\Documenti\\GitHub\\RAG-with-LLamaIndex-Open\\.venv\\lib\\site-packages\\fitz\\__init__.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, filename, stream, filetype, rect, width, height, fontsize)\u001b[0m\n\u001b[0;32m   2787\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_count2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_count_pdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2788\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2789\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_count2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_count_fz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2790\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2791\u001b[1;33m             \u001b[0mJM_mupdf_show_errors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJM_mupdf_show_errors_old\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: no such file: '.\\Docs\\ongitudinal Data Analysis - Master of Science in Biostatistics by Slidesgo.pdf'"
     ]
    }
   ],
   "source": [
    "import pdf_ingestion\n",
    "text = pdf_ingestion.replace_tables_in_text('.\\Docs\\Longitudinal Data Analysis - Master of Science in Biostatistics by Slidesgo.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2307.09288.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EsamiVari_TIZIO_CAIO_5678.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning-pdf.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freelance_Developer_CV.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoice.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagina di Scanned PDF non estratta \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The output file is empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagina di Scanned PDF non estratta \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The output file is empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagina di Scanned PDF non estratta \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The output file is empty.\n",
      "The output file is empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagina di Scanned PDF non estratta \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The output file is empty.\n",
      "The output file is empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagina di Scanned PDF non estratta \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The output file is empty.\n",
      "The output file is empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagina di Scanned PDF non estratta \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The output file is empty.\n",
      "The output file is empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagina di Scanned PDF non estratta \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The output file is empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagina di Scanned PDF non estratta \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The output file is empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagina di Scanned PDF non estratta \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The output file is empty.\n",
      "The output file is empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagina di Scanned PDF non estratta \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The output file is empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagina di Scanned PDF non estratta \n",
      "Pagina di Scanned PDF non estratta \n",
      "Pagina di Scanned PDF non estratta \n",
      "Pagina di Scanned PDF non estratta \n",
      "Pagina di Scanned PDF non estratta \n",
      "Pagina di Scanned PDF non estratta \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The output file is empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagina di Scanned PDF non estratta \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The output file is empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagina di Scanned PDF non estratta \n",
      "Pagina di Scanned PDF non estratta \n",
      "Pagina di Scanned PDF non estratta \n",
      "Pagina di Scanned PDF non estratta \n",
      "Pagina di Scanned PDF non estratta \n",
      "Pagina di Scanned PDF non estratta \n",
      "Pagina di Scanned PDF non estratta \n",
      "Pagina di Scanned PDF non estratta \n",
      "Pagina di Scanned PDF non estratta \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The output file is empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagina di Scanned PDF non estratta \n",
      "Longitudinal Data Analysis - Master of Science in Biostatistics by Slidesgo.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n"
     ]
    },
    {
     "ename": "CSVParseError",
     "evalue": "Error failed to create DataFrame with different column tables.\nTry to set `multiple_tables=True`or set `names` option for `pandas_options`. \n, caused by ParserError('Error tokenizing data. C error: Expected 1 fields in line 3, saw 2\\n')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\SIGNORILEG\\OneDrive - Links S.p.A\\Documenti\\GitHub\\RAG-with-LLamaIndex-Open\\.venv\\lib\\site-packages\\tabula\\io.py:426\u001b[0m, in \u001b[0;36mread_pdf\u001b[1;34m(input_path, output_format, encoding, java_options, pandas_options, multiple_tables, user_agent, use_raw_url, pages, guess, area, relative_area, lattice, stream, password, silent, columns, relative_columns, format, batch, output_path, force_subprocess, options)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [pd\u001b[38;5;241m.\u001b[39mread_csv(io\u001b[38;5;241m.\u001b[39mStringIO(output), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_pandas_options)]\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pd\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mParserError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\SIGNORILEG\\OneDrive - Links S.p.A\\Documenti\\GitHub\\RAG-with-LLamaIndex-Open\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SIGNORILEG\\OneDrive - Links S.p.A\\Documenti\\GitHub\\RAG-with-LLamaIndex-Open\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:624\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SIGNORILEG\\OneDrive - Links S.p.A\\Documenti\\GitHub\\RAG-with-LLamaIndex-Open\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1921\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1916\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1917\u001b[0m     (\n\u001b[0;32m   1918\u001b[0m         index,\n\u001b[0;32m   1919\u001b[0m         columns,\n\u001b[0;32m   1920\u001b[0m         col_dict,\n\u001b[1;32m-> 1921\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1923\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\SIGNORILEG\\OneDrive - Links S.p.A\\Documenti\\GitHub\\RAG-with-LLamaIndex-Open\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 3, saw 2\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCSVParseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m full_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, pdf_file)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(pdf_file)\n\u001b[1;32m---> 12\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mpdf_ingestion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace_tables_in_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SIGNORILEG\\OneDrive - Links S.p.A\\Documenti\\GitHub\\RAG-with-LLamaIndex-Open\\pdf_ingestion.py:51\u001b[0m, in \u001b[0;36mreplace_tables_in_text\u001b[1;34m(pdf_path)\u001b[0m\n\u001b[0;32m     49\u001b[0m new_coordinates \u001b[38;5;241m=\u001b[39m scale_xy(table)\n\u001b[0;32m     50\u001b[0m area \u001b[38;5;241m=\u001b[39m [new_coordinates[\u001b[38;5;241m0\u001b[39m], new_coordinates[\u001b[38;5;241m1\u001b[39m], new_coordinates[\u001b[38;5;241m2\u001b[39m], new_coordinates[\u001b[38;5;241m3\u001b[39m]]\n\u001b[1;32m---> 51\u001b[0m tables \u001b[38;5;241m=\u001b[39m \u001b[43mtabula\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpage_num\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marea\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marea\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiple_tables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tables:\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SIGNORILEG\\OneDrive - Links S.p.A\\Documenti\\GitHub\\RAG-with-LLamaIndex-Open\\.venv\\lib\\site-packages\\tabula\\io.py:434\u001b[0m, in \u001b[0;36mread_pdf\u001b[1;34m(input_path, output_format, encoding, java_options, pandas_options, multiple_tables, user_agent, use_raw_url, pages, guess, area, relative_area, lattice, stream, password, silent, columns, relative_columns, format, batch, output_path, force_subprocess, options)\u001b[0m\n\u001b[0;32m    428\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError failed to create DataFrame with different column tables.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    429\u001b[0m message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry to set `multiple_tables=True`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor set `names` option for `pandas_options`. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    432\u001b[0m )\n\u001b[1;32m--> 434\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m CSVParseError(message, e)\n",
      "\u001b[1;31mCSVParseError\u001b[0m: Error failed to create DataFrame with different column tables.\nTry to set `multiple_tables=True`or set `names` option for `pandas_options`. \n, caused by ParserError('Error tokenizing data. C error: Expected 1 fields in line 3, saw 2\\n')"
     ]
    }
   ],
   "source": [
    "import pdf_ingestion\n",
    "import os\n",
    "\n",
    "folder_path = '.\\Docs'\n",
    "pdf_files = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "\n",
    "chunks = []\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    full_path = os.path.join(folder_path, pdf_file)\n",
    "    print(pdf_file)\n",
    "    text = pdf_ingestion.replace_tables_in_text(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
